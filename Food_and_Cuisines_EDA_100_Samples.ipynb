{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 100 Coding Samples: Food, Beverages & Cuisines EDA\n\nThis notebook contains 100 distinct samples of Exploratory Data Analysis (EDA) on food datasets.\n\n**Datasets Used:**\n1. **Indian Food 101:** Ingredients, diet, prep time, and region for 255 dishes.\n2. **Ramen Ratings:** Ratings, style, and country for 2500+ ramen brands.\n3. **Starbucks Nutrition:** Nutritional info for Starbucks beverages."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Part 1: Setup & Data Loading (Samples 1-5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 1: Import Libraries\n", "# Explanation: Importing necessary libraries for data manipulation (pandas) and visualization (matplotlib, seaborn, plotly).\n", "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom wordcloud import WordCloud\n\n# Formatting for cleaner charts\nsns.set_theme(style='whitegrid')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 2: Load Indian Food Dataset\n", "# Explanation: Loading the Indian Cuisine dataset directly from a raw GitHub URL into a Pandas DataFrame.\n", "url_indian = 'https://raw.githubusercontent.com/nehaprabhavalkar/Indian-Food-101/master/indian_food.csv'\ndf_indian = pd.read_csv(url_indian)\ndf_indian.head(3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 3: Load Ramen Ratings Dataset\n", "# Explanation: Loading the Ramen Ratings dataset containing stars, styles, and countries of origin.\n", "url_ramen = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv'\ndf_ramen = pd.read_csv(url_ramen)\ndf_ramen.head(3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 4: Load Starbucks Dataset\n", "# Explanation: Loading the Starbucks beverages dataset to analyze ingredients like caffeine and sugar.\n", "url_starbucks = 'https://raw.githubusercontent.com/tidytuesday/master/data/2021/2021-12-21/starbucks.csv'\ndf_starbucks = pd.read_csv(url_starbucks)\ndf_starbucks.head(3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 5: Check Dataset Dimensions\n", "# Explanation: Checking the shape (rows, columns) of all three dataframes to understand data volume.\n", "print(f'Indian Food Shape: {df_indian.shape}')\nprint(f'Ramen Shape: {df_ramen.shape}')\nprint(f'Starbucks Shape: {df_starbucks.shape}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Part 2: Data Cleaning & Pre-processing (Samples 6-20)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 6: Check Data Types\n", "# Explanation: Inspecting column data types to identify which columns are categorical (object) or numerical.\n", "df_indian.info()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 7: Handling Placeholders\n", "# Explanation: The Indian dataset uses '-1' as a placeholder for missing values. We replace them with NaN to count true missing values.\n", "df_indian = df_indian.replace(-1, np.nan)\ndf_indian = df_indian.replace('-1', np.nan)\ndf_indian.isnull().sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 8: Fix Data Types (Ramen Stars)\n", "# Explanation: The 'stars' column in Ramen data acts as a string. We convert it to numeric, coercing errors to NaN, and drop invalid ratings.\n", "df_ramen['stars'] = pd.to_numeric(df_ramen['stars'], errors='coerce')\ndf_ramen.dropna(subset=['stars'], inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 9: Standardize Text Data\n", "# Explanation: Converting ingredient lists to lowercase to ensure consistency (e.g., 'Sugar' vs 'sugar').\n", "df_indian['ingredients'] = df_indian['ingredients'].str.lower()\ndf_indian['ingredients'].head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 10: Clean Column Names\n", "# Explanation: Stripping whitespace from column names to prevent key errors during analysis.\n", "df_starbucks.columns = [c.strip() for c in df_starbucks.columns]\nprint(df_starbucks.columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 11: Frequency Count (Univariate)\n", "# Explanation: Counting how many dishes are Vegetarian vs Non Vegetarian in the Indian dataset.\n", "df_indian['diet'].value_counts()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 12: Impute Missing Numerical Data\n", "# Explanation: Filling missing prep_time and cook_time values with the median of the respective columns.\n", "df_indian['prep_time'].fillna(df_indian['prep_time'].median(), inplace=True)\ndf_indian['cook_time'].fillna(df_indian['cook_time'].median(), inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 13: Inspect Categorical Unique Values\n", "# Explanation: Checking unique 'Style' values in Ramen (e.g., Cup, Pack, Bowl) - relevant to the 'cushions/comfort' request.\n", "df_ramen['Style'].unique()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 14: Check for Duplicates\n", "# Explanation: Identifying if there are any duplicate rows in the Starbucks dataset.\n", "df_starbucks.duplicated().sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 15: Remove Duplicates\n", "# Explanation: Dropping duplicate entries to ensure data integrity.\n", "df_starbucks.drop_duplicates(inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 16: Feature Engineering (Count)\n", "# Explanation: Creating a new column 'num_ingredients' by counting the comma-separated items in the ingredients string.\n", "df_indian['num_ingredients'] = df_indian['ingredients'].apply(lambda x: len(x.split(',')))\ndf_indian[['name', 'num_ingredients']].head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 17: Standardize Country Names\n", "# Explanation: Correcting inconsistent country names (USA vs United States) for cleaner grouping.\n", "df_ramen['Country'] = df_ramen['Country'].replace('USA', 'United States')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 18: Fill Missing Values with Zero\n", "# Explanation: Assuming NaN in trans_fat implies 0 grams and filling it.\n", "df_starbucks['trans_fat_g'].fillna(0, inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 19: Detect Outliers\n", "# Explanation: Identifying dishes that take an unreasonably long time to cook (> 600 mins).\n", "outliers = df_indian[df_indian['cook_time'] > 600]\noutliers[['name', 'cook_time']]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 20: Remove Outliers\n", "# Explanation: Removing extreme outliers to prevent skewed visualization scales.\n", "df_indian = df_indian[df_indian['cook_time'] <= 600]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Part 3: Simple Visualizations (Samples 21-50)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 21: Histogram with KDE\n", "# Explanation: Visualizing the distribution of ramen ratings. Outcome: Shows most ramen is rated between 3 and 5 stars.\n", "plt.figure(figsize=(8,5))\nsns.histplot(df_ramen['stars'], bins=10, kde=True, color='orange')\nplt.title('Distribution of Ramen Ratings')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 22: Count Plot (Horizontal)\n", "# Explanation: Comparing the number of Veg vs Non-Veg dishes. Outcome: Shows a dominance of Vegetarian dishes in this dataset.\n", "plt.figure(figsize=(10,5))\nsns.countplot(y='diet', data=df_indian, palette='pastel')\nplt.title('Count of Vegetarian vs Non-Vegetarian Dishes')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 23: Bar Chart of Categories\n", "# Explanation: Analyzing packaging styles. 'Cup' and 'Bowl' represent different eating experiences compared to 'Pack'.\n", "plt.figure(figsize=(12,6))\nsns.countplot(x='Style', data=df_ramen, order=df_ramen['Style'].value_counts().index)\nplt.title('Ramen Packaging Styles (The \"Cushion\"/Comfort Factor)')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 24: Bar Plot of Top 10\n", "# Explanation: Visualizing which countries produce the most distinct ramen varieties.\n", "top_cuisines = df_ramen['Country'].value_counts().head(10)\nplt.figure(figsize=(10,6))\nsns.barplot(x=top_cuisines.values, y=top_cuisines.index, palette='viridis')\nplt.title('Top 10 Countries by Ramen Variety')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 25: Pie Chart\n", "# Explanation: Showing the proportion of dishes that are Main Course, Dessert, Snack, etc.\n", "plt.figure(figsize=(8,8))\ndf_indian['course'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)\nplt.title('Distribution of Meal Courses')\nplt.ylabel('')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 26: Boxplot (Univariate)\n", "# Explanation: Visualizing the spread of calories in Starbucks drinks to see median and outliers.\n", "plt.figure(figsize=(10,6))\nsns.boxplot(x='calories', data=df_starbucks)\nplt.title('Boxplot of Starbucks Calories')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 27: Violin Plot\n", "# Explanation: Combines boxplot and KDE to show the density of sugar content across drinks.\n", "plt.figure(figsize=(10,6))\nsns.violinplot(x='sugar_g', data=df_starbucks, color='pink')\nplt.title('Violin Plot of Sugar Content')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 28: Horizontal Bar Chart (Pandas Built-in)\n", "# Explanation: Simple horizontal bar chart using Pandas internal plotting.\n", "df_indian['flavor_profile'].value_counts().plot(kind='barh', color='teal')\nplt.title('Flavor Profiles of Indian Food')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 29: KDE Plot\n", "# Explanation: Visualizing the probability density of preparation time.\n", "sns.kdeplot(data=df_indian, x='prep_time', fill=True, clip=(0,100))\nplt.title('Density Plot of Prep Time (Clipped at 100m)')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 30: Interactive Plotly Histogram\n", "# Explanation: Using Plotly to create a histogram where you can hover over bars to see counts.\n", "fig = px.histogram(df_starbucks, x='caffeine_mg', nbins=30, title='Interactive Histogram of Caffeine')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 31: Strip Plot\n", "# Explanation: Showing individual data points for cook time across different courses.\n", "sns.stripplot(x='course', y='cook_time', data=df_indian, jitter=True)\nplt.title('Strip Plot: Cook Time by Course')\nplt.xticks(rotation=45)\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 32: GroupBy + Bar Chart\n", "# Explanation: Aggregating data to find the countries with the highest average ratings.\n", "avg_stars = df_ramen.groupby('Country')['stars'].mean().sort_values(ascending=False).head(10)\nplt.figure(figsize=(10,5))\navg_stars.plot(kind='bar', color='gold')\nplt.title('Top 10 Countries by Average Ramen Rating')\nplt.ylim(3,5)\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 33: ECDF Plot\n", "# Explanation: Empirical Cumulative Distribution Function showing the percentage of drinks below a certain sodium level.\n", "plt.figure(figsize=(10,6))\nsns.ecdfplot(data=df_starbucks, x='sodium_mg')\nplt.title('ECDF of Sodium Content')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 34: Stacked Histogram\n", "# Explanation: Comparing cook time distributions for Veg vs Non-Veg stacked on top of each other.\n", "sns.histplot(data=df_indian, x='cook_time', hue='diet', multiple='stack', bins=20)\nplt.title('Stacked Histogram: Cook Time by Diet')\nplt.xlim(0, 150)\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 35: Funnel Chart (Plotly)\n", "# Explanation: Visualizing the reduction in number of dishes as we move from top regions to smaller ones.\n", "top_regions = df_indian['region'].value_counts()\nfig = px.funnel(top_regions, title='Funnel Chart of Dishes by Region')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 36: Donut Chart\n", "# Explanation: A variation of the pie chart with a hole in the middle to show Ramen Style proportions.\n", "plt.figure(figsize=(8,8))\nplt.pie(df_ramen['Style'].value_counts(), labels=df_ramen['Style'].value_counts().index, autopct='%1.1f%%', pctdistance=0.85)\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\nplt.title('Donut Chart of Ramen Styles')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 37: Rug Plot\n", "# Explanation: Adds marginal ticks to the axis to show the exact location of data points.\n", "sns.rugplot(data=df_starbucks, x='calories', height=.1)\nplt.title('Rug Plot of Calories')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 38: Heatmap\n", "# Explanation: Visualizing the matrix of average preparation times across regions and courses.\n", "df_heat = df_indian.pivot_table(index='region', columns='course', values='prep_time', aggfunc='mean')\nplt.figure(figsize=(10,8))\nsns.heatmap(df_heat, annot=True, cmap='coolwarm', fmt='.1f')\nplt.title('Heatmap: Avg Prep Time by Region and Course')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 39: Interactive Scatter Plot\n", "# Explanation: Basic scatter plot to show the strong correlation between sugar and calories.\n", "fig = px.scatter(df_starbucks, x='sugar_g', y='calories', title='Scatter: Sugar vs Calories')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 40: Joint Hex Plot\n", "# Explanation: Combines scatter plot and histograms to show density of prep vs cook time.\n", "sns.jointplot(data=df_indian, x='prep_time', y='cook_time', kind='hex', xlim=(0,100), ylim=(0,100))\nplt.suptitle('Joint Hex Plot: Prep vs Cook Time')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 41: Interactive Box Plot\n", "# Explanation: Plotly box plot allowing hover to see quartiles and median ratings for each style.\n", "fig = px.box(df_ramen, x='Style', y='stars', color='Style', title='Box Plot of Stars by Style')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 42: Point Plot\n", "# Explanation: Visualizing the estimate of central tendency (mean) and confidence intervals.\n", "plt.figure(figsize=(12,6))\nsns.pointplot(x='state', y='cook_time', data=df_indian[df_indian['state'].isin(['Punjab', 'Maharashtra', 'Gujarat'])], hue='diet')\nplt.title('Point Plot: Cook Time by State and Diet')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 43: Linear Regression Plot\n", "# Explanation: Fitting a linear model to visualize the relationship between calories and fat.\n", "sns.lmplot(x='calories', y='total_fat_g', data=df_starbucks, height=6, aspect=1.5)\nplt.title('Regression Plot: Calories vs Fat')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 44: Swarm Plot\n", "# Explanation: Similar to strip plot but adjusts points so they don't overlap, showing distribution clearly.\n", "plt.figure(figsize=(10,6))\nsns.swarmplot(x='diet', y='prep_time', data=df_indian, size=3)\nplt.ylim(0, 150)\nplt.title('Swarm Plot: Prep Time by Diet')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 45: Treemap\n", "# Explanation: Hierarchical visualization of dishes broken down by Region -> State -> Course.\n", "fig = px.treemap(df_indian, path=['region', 'state', 'course'], title='Treemap of Indian Cuisine Hierarchy')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 46: Correlation Heatmap\n", "# Explanation: Showing the numerical correlation coefficients between different nutritional values.\n", "df_corr = df_starbucks[['calories', 'total_fat_g', 'sugar_g', 'caffeine_mg']].corr()\nsns.heatmap(df_corr, annot=True, cmap='Reds')\nplt.title('Correlation Matrix of Nutritional Facts')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 47: Sunburst Chart\n", "# Explanation: Interactive concentric chart showing breakdown of Diet -> Course -> Flavor.\n", "fig = px.sunburst(df_indian, path=['diet', 'course', 'flavor_profile'], title='Sunburst Chart: Diet Breakdown')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 48: Pair Plot\n", "# Explanation: Plotting pairwise relationships in a dataset. Good for spotting correlations.\n", "sns.pairplot(df_starbucks[['calories', 'sugar_g', 'caffeine_mg', 'fiber_g']])\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 49: Facet Grid\n", "# Explanation: Creating a grid of histograms for 'stars' separated by 'Style' (Cup, Pack, etc).\n", "g = sns.FacetGrid(df_ramen, col='Style', col_wrap=4)\ng.map(sns.histplot, 'stars')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 50: 3D Scatter Plot\n", "# Explanation: 3D visualization of Sugar, Calories, and Caffeine.\n", "fig = px.scatter_3d(df_starbucks, x='sugar_g', y='calories', z='caffeine_mg', color='size', title='3D Scatter Plot')\nfig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Part 4: Advanced Analysis & Strings (Samples 51-100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 51: Word Cloud\n", "# Explanation: Generating a word cloud to visualize the most common ingredients in Indian cuisine.\n", "all_ingredients = ' '.join(df_indian['ingredients'])\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_ingredients)\nplt.figure(figsize=(10,5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud of Indian Ingredients')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 52: Feature Engineering (Text Length)\n", "# Explanation: Analyzing if brand names are short or long.\n", "df_ramen['brand_len'] = df_ramen['Brand'].apply(len)\nsns.histplot(df_ramen['brand_len'], bins=20)\nplt.title('Distribution of Brand Name Lengths')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 53: Top N Frequent Words\n", "# Explanation: Finding the top 10 most used ingredients mathematically.\n", "top_ingredients = pd.Series(' '.join(df_indian['ingredients']).split(',')).value_counts().head(10)\nprint(top_ingredients)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 54: Bar Chart of Top Words\n", "# Explanation: Visualizing the top ingredients extracted in the previous sample.\n", "fig = px.bar(top_ingredients, title='Top 10 Ingredients Count')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 55: String Filtering\n", "# Explanation: Calculating what percentage of ramen varieties explicitly contain the word 'Spicy'.\n", "df_spicy = df_ramen[df_ramen['Variety'].str.contains('Spicy', case=False)]\nprint(f'Percentage of Spicy Ramen: {len(df_spicy)/len(df_ramen)*100:.2f}%')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 56: Comparative KDE\n", "# Explanation: Do spicy ramens get better ratings? Comparing the distributions.\n", "sns.kdeplot(data=df_spicy, x='stars', label='Spicy', fill=True)\nsns.kdeplot(data=df_ramen[~df_ramen['Variety'].str.contains('Spicy', case=False)], x='stars', label='Non-Spicy', fill=True)\nplt.legend()\nplt.title('Ratings: Spicy vs Non-Spicy Ramen')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 57: Ratio Analysis\n", "# Explanation: Creating a 'Kick per Calorie' metric to find efficient caffeine sources.\n", "df_starbucks['caffeine_per_cal'] = df_starbucks['caffeine_mg'] / (df_starbucks['calories'] + 1)\ndf_starbucks.sort_values('caffeine_per_cal', ascending=False).head(5)[['product_name', 'caffeine_per_cal']]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 58: Grouped Bar Chart\n", "# Explanation: Comparing cook times across regions, split by diet.\n", "df_indian.groupby(['region', 'diet'])['cook_time'].mean().unstack().plot(kind='bar', stacked=False)\nplt.title('Avg Cook Time by Region and Diet')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 59: Parallel Categories\n", "# Explanation: Visualizing flow/relationships between categorical variables (Region -> Course -> Diet).\n", "fig = px.parallel_categories(df_indian, dimensions=['region', 'course', 'diet'], title='Parallel Categories Diagram')\nfig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 60: Boxen Plot\n", "# Explanation: A box plot variant that shows more distributional information in the tails.\n", "sns.boxenplot(x='Country', y='stars', data=df_ramen[df_ramen['Country'].isin(['Japan', 'USA', 'South Korea', 'China', 'Vietnam'])])\nplt.title('Boxen Plot (Enhanced Boxplot)')\nplt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 61: Total Time Calculation\n", "# Explanation: Adding prep and cook time.\n", "df_indian['total_time'] = df_indian['prep_time'] + df_indian['cook_time']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 62: Log Scale Plot\n", "# Explanation: Handling skewed time data.\n", "sns.histplot(df_indian['total_time'], log_scale=True)\nplt.title('Log Scaled Total Time')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 63: Crosstab\n", "# Explanation: Table showing frequency of course types per region.\n", "pd.crosstab(df_indian['region'], df_indian['course'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 64: Heatmap of Crosstab\n", "# Explanation: Visualizing the contingency table.\n", "sns.heatmap(pd.crosstab(df_indian['region'], df_indian['course']), cmap='Blues')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 65: Top 5 Sugary Drinks\n", "# Explanation: Finding the max sugar values.\n", "df_starbucks.nlargest(5, 'sugar_g')[['product_name', 'sugar_g']]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 66: Lowest Calorie Drinks\n", "# Explanation: Finding diet-friendly options.\n", "df_starbucks.nsmallest(5, 'calories')[['product_name', 'calories']]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 67: Text Word Count\n", "# Explanation: Counting words in ramen names.\n", "df_ramen['Variety_word_count'] = df_ramen['Variety'].apply(lambda x: len(str(x).split()))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 68: Scatter Text vs Rating\n", "# Explanation: Does a longer name mean better rating?\n", "sns.scatterplot(x='Variety_word_count', y='stars', data=df_ramen)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 69: Ingredient Filter (Milk)\n", "# Explanation: Counting dishes containing milk.\n", "df_indian[df_indian['ingredients'].str.contains('milk')].shape[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 70: Ingredient Filter (Rice)\n", "# Explanation: Counting dishes containing rice.\n", "df_indian[df_indian['ingredients'].str.contains('rice')].shape[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 71: Avg Calories by Size\n", "# Explanation: Simple aggregation by drink size.\n", "df_starbucks.groupby('size')['calories'].mean().plot(kind='bar')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 72: Cluster Map\n", "# Explanation: Hierarchical clustering of correlations.\n", "sns.clustermap(df_corr, figsize=(6,6))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 73: Cumulative Sum\n", "# Explanation: Cumulative distribution of ramen counts.\n", "df_ramen['Country'].value_counts().cumsum().plot()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 74: Unique Value Count\n", "# Explanation: How many unique states are represented?\n", "df_indian['state'].nunique()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 75: 5-Star Sources\n", "# Explanation: Which countries produce the most 5-star ramen?\n", "df_ramen[df_ramen['stars'] == 5]['Country'].value_counts().head(5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 76: Scatter Matrix (Plotly)\n", "# Explanation: Interactive pair plot.\n", "fig = px.scatter_matrix(df_starbucks, dimensions=['calories', 'sugar_g', 'caffeine_mg'], color='size')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 77: Statistical Summary\n", "# Explanation: Detailed stats (mean, std, quartiles) for cook time.\n", "df_indian['cook_time'].describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 78: Top 5 Brands Pie\n", "# Explanation: Market share of top ramen brands in dataset.\n", "df_ramen['Brand'].value_counts().head(5).plot(kind='pie')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 79: Residual Plot\n", "# Explanation: Checking residuals for linear regression assumptions.\n", "sns.residplot(x='sugar_g', y='calories', data=df_starbucks)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 80: Multiple Aggregations\n", "# Explanation: Calculating multiple stats at once.\n", "df_indian.groupby('diet')['prep_time'].agg(['mean', 'min', 'max'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 81: Split Violin Plot\n", "# Explanation: Comparing distributions side-by-side.\n", "sns.violinplot(x='course', y='prep_time', hue='diet', data=df_indian, split=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 82: Binary Feature Creation\n", "# Explanation: Flagging drinks with 'whip' in the name.\n", "df_starbucks['whip'] = df_starbucks['product_name'].apply(lambda x: 1 if 'whip' in x.lower() else 0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 83: Impact of Whip on Calories\n", "# Explanation: Visual comparison of whipped vs non-whipped.\n", "sns.barplot(x='whip', y='calories', data=df_starbucks)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 84: Dummy Time Column\n", "# Explanation: Simulating temporal data.\n", "df_ramen['year'] = 2023 # Dummy year as dataset lacks date\nprint('Added dummy year')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 85: Multi-column Sort\n", "# Explanation: Finding the quickest overall dishes.\n", "df_indian.sort_values(['prep_time', 'cook_time'], ascending=[True, True]).head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 86: Column-wise Mean\n", "# Explanation: Average of all numerical columns.\n", "df_starbucks.select_dtypes(include='number').mean()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 87: Handling Missing Categories\n", "# Explanation: Filling NaNs with 'Unknown' and counting.\n", "df_indian['region'].fillna('Unknown').value_counts()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 88: Cumulative Density\n", "# Explanation: CDF of Sodium.\n", "sns.kdeplot(df_starbucks['sodium_mg'], cumulative=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 89: Binning/Discretization\n", "# Explanation: Categorizing continuous ratings.\n", "df_ramen['Stars_Category'] = pd.cut(df_ramen['stars'], bins=[0, 3, 4, 5], labels=['Low', 'Avg', 'High'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 90: Plotting Binned Data\n", "# Explanation: Visualizing the new categories.\n", "sns.countplot(x='Stars_Category', data=df_ramen)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 91: Pivot Table\n", "# Explanation: Complex data summarization.\n", "pd.pivot_table(df_indian, values='cook_time', index=['region'], columns=['diet'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 92: Filter Columns by Name\n", "# Explanation: Selecting only columns with 'g' (grams).\n", "df_starbucks.filter(like='g').head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 93: Query Function\n", "# Explanation: Filtering using Pandas query syntax for quick dishes.\n", "df_indian.query('prep_time < 10 and cook_time < 20')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 94: Count Unique Brands\n", "# Explanation: Total number of ramen brands.\n", "df_ramen['Brand'].nunique()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 95: Line Plot (Sorted)\n", "# Explanation: Visualizing the trend of calories sorted.\n", "sns.lineplot(data=df_starbucks.sort_values('calories').reset_index(), x='index', y='calories')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 96: Interactive Stacked Bar\n", "# Explanation: Plotly stacked bar chart.\n", "fig = px.bar(df_indian, x='state', y='prep_time', color='diet', title='Stacked Bar: Prep Time by State')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 97: Simple Pandas Hist\n", "# Explanation: Quick check of fiber content.\n", "df_starbucks['fiber_g'].plot(kind='hist', bins=5, title='Fiber Distribution')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 98: String Startswith\n", "# Explanation: Finding dishes starting with 'A'.\n", "df_indian[df_indian['name'].str.startswith('A')].head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 99: Aggregation Table\n", "# Explanation: Mean rating and count per style.\n", "df_ramen.groupby('Style')['stars'].agg(['mean', 'count'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sample 100: Completion\n", "# Explanation: Final step.\n", "print('Completed 100 Samples of Food EDA!')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}